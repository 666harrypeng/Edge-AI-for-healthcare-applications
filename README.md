
# VAE-LSTM Anomaly Detection (PyTorch-Based) - V1.0

* `Doc last Updated`: Dec 31, 2024 - 23:45
* `Contributor`: Yiyan PENG (regulating branch ***model_design***)

## Repo General Structures

There are two folders:

* ***datasets*** $\rightarrow$ stores raw time-series datasets in ***csv*** files and preprocess datasets in ***npz*** files.
* ***pytorch_ypengbb*** $\rightarrow$ all code files. 

## Data Preparation

* The shape of raw data in `csv` files should be: (1) First column is the timestamps (2) The following columns should be the sensor readings. ***<NOTE>: Current version supposes sensor readings are one-dimension (each reading is a single value instead of a vector) but can have multimodal sensors.*** 

* Raw data in `../datasets/NAB-known-anomaly/csv-files` should first be preprocessed in `preprocess_NAB_data.py`. Preprocessing contains data normalization, dataset split, creating ***non-overlapping*** rolling windows, and generating `npz` files. The dictionary keys and values from npz files should refer to the preprocess file. The npz files will be automatically saved during preprocessing execution. 

* All the anomalies' timestamps should be explicitly specified before the preprocessing. 

* All the hyperparameters' settings are stored in `pytorch_NAB_config.json` file. So, the json file should be checked before all code execution.

## Main Code

* ***PLEASE ALWAYS ATTENTION:*** Check the JSON configuration file before the main code's execution. 

* ***Current general workflow:*** (1) Load & preprocess data (2) Train VAE / Load checkpoint (best) VAE model. (3) Train LSTM based on embeddings generated by the best VAE model's encoder module / Load checkpoint (best) LSTM model. (4) Detect anomalies.

To run the main code:

```python
cd ./pytorch_ypengbb
python pytorch_anomaly_detection_main.py -c pytorch_NAB_config.json
```

## Core Model Definition

### VAE

General ideas: Encoder (learn data features) $\rightarrow$ Latent Space Gaussian Sampling $\rightarrow$ Decoder (reconstruct data).

From JSON file, specify `time window length`, `number of input channels (sensor counts)`, `latent space dimension`, and `number of hidden layer units` of CNN layers. 

#### Encoder

Model Base: 2D CNN, 5 layers, (3, 1) kernel, 1 stride, 1 padding

#### Decoder

Model Base: 2D Transpose CNN, 5 layers, (3, 1) kernel, 1 stride, 1 padding

### LSTM

From JSON file, specify `number of time steps per input batch`, `number of hidden units in LSTM's model`, `latent space dimension`, `number of future steps to predict`, `LSTM layer number`, and `training batch size`. 

## Training Key Details

* There are many places with `assert` for checking the shape of data flow. Basically, these requirements should always be there to follow.

* For anomaly detection section (mainly in `compute_anomaly_scores(...)` function), final error consists of two parts - VAE's reconstrution errors and VAE&LSTM prediction errors. Prediction errors are calculated with the actual predicted values after VAE's decoder. 

* Anomaly score calculation ratio can be adjusted in `compute_anomaly_scores(...)` function. The default settings: anomaly scores <- 1 * reconstruction errors + 0.5 * prediction errors

* The portion of LSTM's prediction length can be adjusted by `l_seq`

